# Arabic Dialect Recognition â€” Hybrid Deep Learning and Signal Processing

This repository contains the complete implementation of a research project investigating hybrid models for Arabic dialect classification using combinations of classical signal processing techniques and deep learning architectures. The experiments explore Mel-Frequency Cepstral Coefficients (MFCC) and Discrete Wavelet Transform (DWT) features in conjunction with Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).

The research evaluates four hybrid configurations:
- MFCC + CNN
- MFCC + RNN
- Wavelet + CNN
- Wavelet + RNN

## ğŸ“ Project Structure

arabic-dialect-recognition-hybrid/
â”œâ”€â”€ data_scripts/ # Dataset loading, filtering, preprocessing, and splitting
â”‚ â”œâ”€â”€ load_commonvoice.py
â”‚ â”œâ”€â”€ preprocess_audio.py
â”‚ â””â”€â”€ split_train_val.py
â”œâ”€â”€ feature_extraction/ # Feature extraction scripts
â”‚ â”œâ”€â”€ extract_mfcc.py
â”‚ â””â”€â”€ extract_wavelet.py
â”œâ”€â”€ experiments/ # Experiment scripts for training each model
â”‚ â”œâ”€â”€ mfcc_cnn_train.py
â”‚ â”œâ”€â”€ mfcc_rnn_train.py
â”‚ â”œâ”€â”€ wavelet_cnn_train.py
â”‚ â””â”€â”€ wavelet_rnn_train.py
â”œâ”€â”€ evaluation/ # Evaluation scripts (classification report + confusion matrices)
â”‚ â”œâ”€â”€ generate_confusion_matrices.py
â”‚ â””â”€â”€ print_classification_report.py
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation

csharp
Copy
Edit

## ğŸ“¦ Installation Requirements

Install the required Python packages using:

```bash
pip install -r requirements.txt
Tested with Python â‰¥ 3.8.

ğŸ—‚ Dataset
The experiments use the Arabic subset of Common Voice 12.0, a large, crowd-sourced multilingual speech dataset. Dialects are assigned based on speaker country metadata:

Egyptian Arabic â†’ Egypt

Levantine Arabic â†’ Jordan, Palestine, Lebanon, Syria

Gulf Arabic â†’ Saudi Arabia, UAE, Qatar, Kuwait

The dataset was filtered, resampled to 16 kHz, and normalized before feature extraction. Approx. 6 hours of speech were used across the three dialect groups.

ğŸ§° Usage Workflow
1ï¸âƒ£ Load and filter dataset:

bash
python data_scripts/load_commonvoice.py
2ï¸âƒ£ Preprocess audio files (resample, normalize, trim):

bash
python data_scripts/preprocess_audio.py
3ï¸âƒ£ Split dataset into training and validation sets:

bash
python data_scripts/split_train_val.py
4ï¸âƒ£ Extract features:

bash
python feature_extraction/extract_mfcc.py      # for MFCC-based models
python feature_extraction/extract_wavelet.py   # for Wavelet-based models
5ï¸âƒ£ Run experiments (train models):


python experiments/mfcc_cnn_train.py
python experiments/mfcc_rnn_train.py
python experiments/wavelet_cnn_train.py
python experiments/wavelet_rnn_train.py
6ï¸âƒ£ Evaluate models:

bash

python evaluation/generate_confusion_matrices.py
python evaluation/print_classification_report.py
ğŸ“„ Citation
If you use this code in your academic work, please cite the associated paper or this repository.

ğŸ“§ Contact
Developed by Ghazal Shwayat
GitHub: https://github.com/YOUR_GITHUB_USERNAME
